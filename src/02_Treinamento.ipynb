{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script de Treinamento de Modelos de Machine Learning para Análise de Sentimentos\n",
    "\n",
    "Este script realiza o treinamento e avaliação de vários modelos de machine learning para a análise de sentimentos em textos. \n",
    "Utiliza uma abordagem de vetorização de texto (TF-IDF) e diferentes algoritmos de classificação como Random Forest, Regressão Logística e Gradient Boosting para identificar o sentimento expresso nos textos. \n",
    "O processo inclui carregar dados, preparar os textos e rótulos, criar pipelines de processamento, realizar busca de hiperparâmetros com validação cruzada, e avaliar os modelos com métricas como acurácia e relatório de classificação.\n",
    "\n",
    "Funcionalidades:\n",
    "- Carregamento de dados de um arquivo CSV.\n",
    "- Preparação e codificação dos textos e rótulos.\n",
    "- Criação de pipelines de machine learning para vetorização e classificação.\n",
    "- Busca de hiperparâmetros utilizando RandomizedSearchCV para otimizar os modelos.\n",
    "- Avaliação dos modelos utilizando acurácia e relatório de classificação detalhado.\n",
    "- Salvamento dos modelos com melhor desempenho.\n",
    "\n",
    "Dependências:\n",
    "- Pandas e NumPy para manipulação de dados.\n",
    "- Scikit-learn para criação de pipelines, modelos de classificação, busca de hiperparâmetros e avaliação.\n",
    "- Joblib para salvar os modelos treinados.\n",
    "\n",
    "Membros do grupo:\n",
    "\n",
    "Alonso Batista de Oliveira Júnior\n",
    "André Moreira de Carvalho\n",
    "Gustavo Castro Candeia\n",
    "Halex Maciel Silva Vieira\n",
    "Welbert Luiz Silva Junior\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict, Any\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix, cohen_kappa_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import joblib\n",
    "import logging\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de constantes para o caminho dos arquivos\n",
    "DATA_FILE_PATH = '../data/cleaned_dataset.csv'\n",
    "MODEL_DIR = '../models'\n",
    "LOG_DIR = '../logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the log to a file in the logs directory\n",
    "logging.basicConfig(filename=f'{LOG_DIR}/training.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS: Dict[str, Dict[str, Any]] = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [300, 500],\n",
    "            'clf__max_depth': [30, 50]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [300, 500],\n",
    "            'clf__learning_rate': [0.01, 0.001]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(filepath, usecols=['Clean_Text', 'Label'])\n",
    "    except FileNotFoundError as e:\n",
    "        logging.error(f\"Arquivo não encontrado: {filepath}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, LabelEncoder]:\n",
    "    \"\"\"Prepara os dados para treinamento, retornando conjuntos de treino e teste, e o LabelEncoder.\"\"\"\n",
    "    df['Clean_Text'] = df['Clean_Text'].fillna('').astype(str)\n",
    "    texts = df['Clean_Text'].values\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    labels = encoder.fit_transform(df['Label'])\n",
    "    \n",
    "    # Imprime os labels e seus códigos\n",
    "    print(\"Classes codificadas e seus códigos:\")\n",
    "    for label, code in zip(encoder.classes_, range(len(encoder.classes_))):\n",
    "        print(f\"Label '{label}' é codificado como {code}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    return train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels), encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model: Any) -> Pipeline:\n",
    "    return Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=2000)),\n",
    "        ('clf', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_metrics(y_test: np.ndarray, predicted_probabilities: np.ndarray, predictions: np.ndarray) -> Dict[str, Any]:\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predicted_probabilities, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"f1_score\": f1,\n",
    "        \"kappa_score\": kappa,\n",
    "        \"roc_auc_per_class\": roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: Pipeline, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Any]:\n",
    "    try:\n",
    "        predictions = model.predict(X_test)\n",
    "        predicted_probabilities = model.predict_proba(X_test)  # Assegurar que estamos usando predict_proba para ROC AUC\n",
    "\n",
    "        base_metrics = {\n",
    "            'classification_report': classification_report(y_test, predictions, output_dict=True),\n",
    "            'accuracy': accuracy_score(y_test, predictions),\n",
    "            'roc_auc': roc_auc_score(y_test, predicted_probabilities, multi_class='ovr', average='weighted')\n",
    "        }\n",
    "\n",
    "        add_metrics = additional_metrics(y_test, predicted_probabilities, predictions)  # Passar predicted_probabilities aqui também\n",
    "        base_metrics.update(add_metrics)\n",
    "        return base_metrics\n",
    "    except NotFittedError as e:\n",
    "        logging.error(\"Modelo não ajustado\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao avaliar o modelo: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    df = load_data(DATA_FILE_PATH)\n",
    "    (X_train, X_test, y_train, y_test), label_encoder = prepare_data(df)\n",
    "    joblib.dump(label_encoder, f'{MODEL_DIR}/label_encoder.joblib')\n",
    "\n",
    "    model_performances = []\n",
    "\n",
    "    for name, config in tqdm(MODEL_CONFIGS.items(), desc=\"Treinando modelos\"):\n",
    "        pipeline = create_pipeline(config['model'])\n",
    "        search = RandomizedSearchCV(pipeline, config['params'], cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "        search.fit(X_train, y_train)\n",
    "        metrics = evaluate_model(search.best_estimator_, X_test, y_test)\n",
    "        logging.info(f\"Relatório de classificação para {name}:\\n{metrics['classification_report']}\")\n",
    "        model_performances.append((name, metrics['accuracy'], metrics['roc_auc'], search.best_estimator_))\n",
    "        logging.info(f\"Melhores hiperparâmetros para {name}: {search.best_params_}\")\n",
    "        logging.info(f\"Acurácia para {name}: {metrics['accuracy']:.4f}\")\n",
    "        logging.info(f\"ROC-AUC para {name}: {metrics['roc_auc']:.4f}\")\n",
    "        logging.info(f\"Melhor modelo para {name}: {search.best_estimator_}\\n\")\n",
    "\n",
    "    model_performances.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, (name, acc, auc, model) in enumerate(model_performances, 1):\n",
    "        model_path = f'{MODEL_DIR}/top_{i}_{name}_model.joblib'\n",
    "        joblib.dump(model, model_path)\n",
    "        logging.info(f\"Modelo {name} salvo com acurácia de {acc:.4f} em {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes codificadas e seus códigos:\n",
      "Label 'litigious' é codificado como 0\n",
      "Label 'negative' é codificado como 1\n",
      "Label 'positive' é codificado como 2\n",
      "Label 'uncertainty' é codificado como 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando modelos:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando modelos:  50%|█████     | 1/2 [56:07<56:07, 3367.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando modelos: 100%|██████████| 2/2 [4:32:50<00:00, 8185.20s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
