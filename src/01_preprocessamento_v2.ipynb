{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script de Pré-processamento de Dados para Análise de Sentimentos\n",
    "\n",
    "Este script é responsável pelo pré-processamento de um dataset de textos para serem usados na análise de sentimentos. \n",
    "O objetivo é limpar e preparar os dados para que modelos de machine learning possam operar de forma eficiente. \n",
    "Este processo inclui a remoção de URLs, menções de usuários, hashtags, caracteres especiais, e palavras de parada (stopwords). \n",
    "Adicionalmente, o script realiza o balanceamento de rótulos para evitar viéses em categorias com super-representação.\n",
    "\n",
    "Funcionalidades:\n",
    "- Limpeza de textos para remover elementos indesejáveis como URLs, menções, hashtags e caracteres não alfabéticos.\n",
    "- Remoção de stopwords para reduzir a dimensionalidade dos dados e focar em palavras significativas.\n",
    "- Balanceamento de rótulos através de undersampling, garantindo que todas as classes de sentimentos sejam igualmente representadas.\n",
    "- Filtragem por idioma para processar apenas textos em inglês.\n",
    "\n",
    "O script é modular, permitindo que cada função seja reutilizada em outros contextos de pré-processamento de texto conforme necessário.\n",
    "\n",
    "Dependências:\n",
    "- Pandas: Para manipulação de dados.\n",
    "- NLTK: Para ferramentas de processamento de texto como tokenização e remoção de stopwords.\n",
    "- Scikit-learn: Para técnicas de resampling usadas no balanceamento de rótulos.\n",
    "- Regex (re): Para expressões regulares utilizadas na limpeza de texto.\n",
    "\n",
    "O fluxo do script inclui carregar os dados, aplicar funções de limpeza e remoção de stopwords, balancear os rótulos e salvar o dataset processado para uso posterior. \n",
    "\n",
    "Membros do grupo:\n",
    "\n",
    "Alonso Batista de Oliveira Júnior\n",
    "André Moreira de Carvalho\n",
    "Gustavo Castro Candeia\n",
    "Halex Maciel Silva Vieira\n",
    "Welbert Luiz Silva Junior\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.utils import resample\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\halex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\halex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Fazendo o download de recursos necessários do NLTK para processamento de texto\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Definindo as stopwords em inglês como uma constante para uso repetido, o que melhora a eficiência\n",
    "STOP_WORDS_EN = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url_mentions(text: str) -> str:\n",
    "    \"\"\"Remove URLs e menções de usuários do texto.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto original.\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto limpo sem URLs e menções.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs que começam com http\n",
    "    text = re.sub(r\"www.\\S+\", '', text)  # Remove URLs que começam com www\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # Remove menções a usuários\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hashtags_special_chars(text: str) -> str:\n",
    "    \"\"\"Remove hashtags e caracteres especiais do texto.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto a ser limpo.\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto limpo de hashtags e caracteres não alfabéticos.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'#[A-Za-z0-9_]+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove caracteres que não são letras ou espaços\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Orquestra a limpeza de URLs, menções, hashtags e caracteres especiais no texto.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto original possivelmente contendo URLs, menções, hashtags e caracteres especiais.\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto limpo.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = clean_url_mentions(text)\n",
    "    text = clean_hashtags_special_chars(text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip().lower()  # Reduz múltiplos espaços para um único espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text: str) -> str:\n",
    "    \"\"\"Remove palavras de parada (stopwords) do texto.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto original tokenizado.\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto sem stopwords.\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text)  # Tokeniza o texto em palavras individuais\n",
    "    return ' '.join([token.lower() for token in tokens if token.lower() not in STOP_WORDS_EN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aplica as funções de pré-processamento no dataframe e filtra dados relevantes.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe contendo coluna de texto para limpeza.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe filtrado e processado.\n",
    "    \"\"\"\n",
    "    df['Clean_Text'] = df['Text'].apply(clean_text)  # Limpeza inicial do texto\n",
    "    df['Clean_Text_LSTM'] = df['Text'].apply(clean_text) # Limpeza inicial do texto para uso em LSTM (Mantém as stop words) \n",
    "    df_filtered = df[(df['Language'] == 'en')].copy()  # Filtra por idioma inglês \n",
    "    df_filtered['Clean_Text'] = df_filtered['Clean_Text'].apply(remove_stopwords)  # Remove stopwords\n",
    "    df_filtered = df_filtered.drop_duplicates(subset=['Clean_Text'])  # Remove textos duplicados\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_labels(df: pd.DataFrame, labels: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Realiza undersampling para balancear os rótulos.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe com desbalanceamento de rótulos.\n",
    "        labels (List[str]): Lista de rótulos a serem balanceados.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe com rótulos balanceados.\n",
    "    \"\"\"\n",
    "    label_counts = df['Label'].value_counts()\n",
    "    min_count = label_counts.min()\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        df_label = df[df['Label'] == label]\n",
    "        df_label_downsampled = resample(df_label, replace=False, n_samples=min_count, random_state=42)\n",
    "        dfs.append(df_label_downsampled)\n",
    "    return pd.concat(dfs).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de caminhos de arquivo\n",
    "data_dir = '../data'\n",
    "input_file = os.path.join(data_dir, 'dataset.csv')\n",
    "output_file = os.path.join(data_dir, 'cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "positive       264545\n",
      "negative       262220\n",
      "uncertainty    206940\n",
      "litigious      204149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Carrega dados\n",
    "df = pd.read_csv(input_file)\n",
    "print(df['Label'].value_counts())  # Mostra a distribuição inicial dos rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "negative       229658\n",
      "positive       221604\n",
      "uncertainty    188989\n",
      "litigious      164189\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Label</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Clean_Text_LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Charlie_Corley @Kristine1G @amyklobuchar @Sty...</td>\n",
       "      <td>en</td>\n",
       "      <td>litigious</td>\n",
       "      <td>testimony evidence court law state federal mus...</td>\n",
       "      <td>testimony is not evidence in a court of law st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t.co/YJNiO0p1JV Flagstar Bank disclose...</td>\n",
       "      <td>en</td>\n",
       "      <td>litigious</td>\n",
       "      <td>flagstar bank discloses data breach impacted m...</td>\n",
       "      <td>flagstar bank discloses a data breach that imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rwanda is set to host the headquarters of Unit...</td>\n",
       "      <td>en</td>\n",
       "      <td>positive</td>\n",
       "      <td>rwanda set host headquarters united nations de...</td>\n",
       "      <td>rwanda is set to host the headquarters of unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OOPS. I typed her name incorrectly (today’s br...</td>\n",
       "      <td>en</td>\n",
       "      <td>litigious</td>\n",
       "      <td>oops typed name incorrectly todays brave witne...</td>\n",
       "      <td>oops i typed her name incorrectly todays brave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It sucks for me since I'm focused on the natur...</td>\n",
       "      <td>en</td>\n",
       "      <td>negative</td>\n",
       "      <td>sucks since im focused nature aspect things en...</td>\n",
       "      <td>it sucks for me since im focused on the nature...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language      Label  \\\n",
       "0  @Charlie_Corley @Kristine1G @amyklobuchar @Sty...       en  litigious   \n",
       "2  https://t.co/YJNiO0p1JV Flagstar Bank disclose...       en  litigious   \n",
       "3  Rwanda is set to host the headquarters of Unit...       en   positive   \n",
       "4  OOPS. I typed her name incorrectly (today’s br...       en  litigious   \n",
       "5  It sucks for me since I'm focused on the natur...       en   negative   \n",
       "\n",
       "                                          Clean_Text  \\\n",
       "0  testimony evidence court law state federal mus...   \n",
       "2  flagstar bank discloses data breach impacted m...   \n",
       "3  rwanda set host headquarters united nations de...   \n",
       "4  oops typed name incorrectly todays brave witne...   \n",
       "5  sucks since im focused nature aspect things en...   \n",
       "\n",
       "                                     Clean_Text_LSTM  \n",
       "0  testimony is not evidence in a court of law st...  \n",
       "2  flagstar bank discloses a data breach that imp...  \n",
       "3  rwanda is set to host the headquarters of unit...  \n",
       "4  oops i typed her name incorrectly todays brave...  \n",
       "5  it sucks for me since im focused on the nature...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processa dados\n",
    "df_processed = preprocess_dataframe(df)\n",
    "print(df_processed['Label'].value_counts())  # Mostra a distribuição dos rótulos após processamento\n",
    "df_processed.head()  # Exibe as primeiras linhas do dataframe processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "uncertainty    164189\n",
      "litigious      164189\n",
      "negative       164189\n",
      "positive       164189\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balanço de Rótulos\n",
    "labels = ['positive', 'negative', 'uncertainty', 'litigious']\n",
    "df_balanced = balance_labels(df_processed, labels)\n",
    "print(df_balanced['Label'].value_counts())  # Mostra a distribuição dos rótulos após balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Clean_Text_LSTM</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear lebron ready post anything social media ...</td>\n",
       "      <td>it was clear lebron was not ready to post anyt...</td>\n",
       "      <td>uncertainty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maybe stop tweeting hire good criminal defense...</td>\n",
       "      <td>maybe you should stop tweeting and hire some g...</td>\n",
       "      <td>litigious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyway main question four domains match lovesi...</td>\n",
       "      <td>anyway the main question is which of these fou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah ok thanks saw clips looked like quite heavy...</td>\n",
       "      <td>ah ok thanks for that just saw some clips of w...</td>\n",
       "      <td>uncertainty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi ravi ji seen trades looks solid wanted conn...</td>\n",
       "      <td>hi ravi ji have seen few of your trades and lo...</td>\n",
       "      <td>uncertainty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Clean_Text  \\\n",
       "0  clear lebron ready post anything social media ...   \n",
       "1  maybe stop tweeting hire good criminal defense...   \n",
       "2  anyway main question four domains match lovesi...   \n",
       "3  ah ok thanks saw clips looked like quite heavy...   \n",
       "4  hi ravi ji seen trades looks solid wanted conn...   \n",
       "\n",
       "                                     Clean_Text_LSTM        Label  \n",
       "0  it was clear lebron was not ready to post anyt...  uncertainty  \n",
       "1  maybe you should stop tweeting and hire some g...    litigious  \n",
       "2  anyway the main question is which of these fou...     negative  \n",
       "3  ah ok thanks for that just saw some clips of w...  uncertainty  \n",
       "4  hi ravi ji have seen few of your trades and lo...  uncertainty  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.columns\n",
    "\n",
    "# seleciona apenas as colunas necessárias\n",
    "df_balanced = df_balanced[['Clean_Text', 'Clean_Text_LSTM','Label']]\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva dados processados e balanceados\n",
    "df_balanced.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
